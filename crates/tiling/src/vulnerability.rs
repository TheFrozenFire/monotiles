//! Recoverability vulnerability analysis for hat tiling deflation.
//!
//! Maps the recoverability landscape: per-position criticality, minimum
//! determining sets, erasure fuzzing, and dependency chains. Built on the
//! one-way analysis infrastructure.

use std::collections::{BTreeMap, HashMap, HashSet};

use crate::metatile::{
    supertile_composition, InflationRule, MetatileType, SUPERTILE_F_CHILDREN,
    SUPERTILE_H_CHILDREN, SUPERTILE_P_CHILDREN, SUPERTILE_T_CHILDREN,
};
use crate::oneway::{
    build_flat_hierarchy, full_sibling_adjacency, neighborhood, type_signature, FlatHierarchy,
    TypeSignature,
};

/// Child index lists for each supertile type, in canonical order (H, T, P, F).
const SUPERTILE_CHILDREN: [&[usize]; 4] = [
    SUPERTILE_H_CHILDREN,
    SUPERTILE_T_CHILDREN,
    SUPERTILE_P_CHILDREN,
    SUPERTILE_F_CHILDREN,
];

const SUPERTILE_NAMES: [&str; 4] = ["H'", "T'", "P'", "F'"];

// ---------------------------------------------------------------------------
// Swap vulnerability
// ---------------------------------------------------------------------------

/// A pair of supertile types whose compositions differ by exactly one tile.
///
/// This represents the minimal boundary vulnerability: reassigning a single
/// tile between adjacent supertiles could turn one type into another.
#[derive(Clone, Debug, PartialEq, Eq)]
pub struct SwapRecord {
    /// The supertile with fewer tiles of the differing type.
    pub source_supertile: MetatileType,
    /// The supertile with more tiles of the differing type.
    pub target_supertile: MetatileType,
    /// The metatile type that differs (adding one of this type to source yields target).
    pub differing_type: MetatileType,
    /// source has this many children, target has source_size + 1.
    pub source_size: usize,
}

/// For each ordered pair of supertile types, check if their compositions
/// differ by exactly one tile in exactly one type component.
///
/// P'=[2,0,1,2] (5 children) and F'=[2,0,1,3] (6 children) differ by
/// exactly one F tile — the only such pair. This makes the F-type positions
/// at P'/F' boundaries the most vulnerable to misassignment.
pub fn enumerate_valid_swaps() -> Vec<SwapRecord> {
    let comp = supertile_composition();
    let all_types = MetatileType::all();
    let mut swaps = Vec::new();

    for (src_idx, &src_type) in all_types.iter().enumerate() {
        let src_comp = comp[src_idx];
        let src_total: usize = src_comp.iter().sum();

        for (tgt_idx, &tgt_type) in all_types.iter().enumerate() {
            if tgt_idx == src_idx {
                continue;
            }
            let tgt_comp = comp[tgt_idx];

            // Check if compositions differ by exactly +1 in one component, 0 in rest
            let mut diff_idx = None;
            let mut valid = true;
            for j in 0..4 {
                let d = tgt_comp[j] as i64 - src_comp[j] as i64;
                match d {
                    0 => {}
                    1 => {
                        if diff_idx.is_some() {
                            valid = false;
                            break;
                        }
                        diff_idx = Some(j);
                    }
                    _ => {
                        valid = false;
                        break;
                    }
                }
            }

            if valid {
                if let Some(di) = diff_idx {
                    swaps.push(SwapRecord {
                        source_supertile: src_type,
                        target_supertile: tgt_type,
                        differing_type: all_types[di],
                        source_size: src_total,
                    });
                }
            }
        }
    }

    swaps
}

// ---------------------------------------------------------------------------
// Per-position criticality
// ---------------------------------------------------------------------------

/// Criticality of a single child position within a supertile.
#[derive(Clone, Debug)]
pub struct PositionCriticality {
    pub supertile: MetatileType,
    /// Position index within the supertile's child list.
    pub position: usize,
    /// The metatile type at this position.
    pub child_type: MetatileType,
    /// 0 = redundant (supertile still identifiable without this position).
    /// 1 = critical (supertile becomes ambiguous without it).
    pub score: u8,
    /// Which other supertile types this becomes confused with when masked.
    pub confused_with: Vec<MetatileType>,
}

/// For each supertile type and child position, compute criticality:
/// does erasing this position's type make the supertile ambiguous?
pub fn compute_position_criticality() -> Vec<PositionCriticality> {
    let comp = supertile_composition();
    let rules = crate::metatile::inflation_rules();
    let child_type_of = |idx: usize| -> MetatileType {
        match &rules[idx] {
            InflationRule::Seed(t) => *t,
            InflationRule::Adjacent { child_type, .. } => *child_type,
            InflationRule::Bridge { child_type, .. } => *child_type,
        }
    };
    let all_types = MetatileType::all();
    let mut results = Vec::new();

    for (st_idx, &st_type) in all_types.iter().enumerate() {
        let children = SUPERTILE_CHILDREN[st_idx];

        for (pos, &child_rule_idx) in children.iter().enumerate() {
            let child_type = child_type_of(child_rule_idx);

            // Mask this position: the remaining children form a partial composition
            let mut partial = comp[st_idx];
            partial[child_type.index()] -= 1;

            // Check which supertile types could match with ANY single tile added
            let mut confused_with = Vec::new();
            for (other_idx, &other_type) in all_types.iter().enumerate() {
                if other_idx == st_idx {
                    continue;
                }
                // Can the other supertile's composition be formed by adding
                // exactly one tile (of any type) to our partial composition?
                let other_comp = comp[other_idx];
                let mut diff_sum = 0i64;
                let mut any_negative = false;
                for j in 0..4 {
                    let d = other_comp[j] as i64 - partial[j] as i64;
                    if d < 0 {
                        any_negative = true;
                        break;
                    }
                    diff_sum += d;
                }
                if !any_negative && diff_sum == 1 {
                    confused_with.push(other_type);
                }
            }

            let score = if confused_with.is_empty() { 0 } else { 1 };

            results.push(PositionCriticality {
                supertile: st_type,
                position: pos,
                child_type,
                score,
                confused_with,
            });
        }
    }

    results
}

// ---------------------------------------------------------------------------
// Minimum determining sets
// ---------------------------------------------------------------------------

/// A minimal subset of child positions that uniquely identifies a supertile.
#[derive(Clone, Debug)]
pub struct DeterminingSet {
    pub supertile: MetatileType,
    /// Positions (indices into supertile's child list) in this determining set.
    pub positions: Vec<usize>,
    /// Size of the minimum determining set.
    pub size: usize,
}

/// For each supertile type, find the smallest subset of child positions whose
/// types uniquely identify the supertile among all 4 types.
pub fn minimum_determining_sets() -> Vec<DeterminingSet> {
    let rules = crate::metatile::inflation_rules();
    let child_type_of = |idx: usize| -> MetatileType {
        match &rules[idx] {
            InflationRule::Seed(t) => *t,
            InflationRule::Adjacent { child_type, .. } => *child_type,
            InflationRule::Bridge { child_type, .. } => *child_type,
        }
    };
    let all_types = MetatileType::all();
    let mut results = Vec::new();

    for (st_idx, &st_type) in all_types.iter().enumerate() {
        let children = SUPERTILE_CHILDREN[st_idx];
        let n = children.len();

        // Get the type list for this supertile's children
        let child_types: Vec<MetatileType> =
            children.iter().map(|&idx| child_type_of(idx)).collect();

        // Build type lists for all 4 supertile types so we can compare subsets
        let all_child_types: Vec<Vec<MetatileType>> = (0..4)
            .map(|si| {
                SUPERTILE_CHILDREN[si]
                    .iter()
                    .map(|&idx| child_type_of(idx))
                    .collect()
            })
            .collect();

        // Brute-force: try subsets of increasing size
        let mut found = false;
        for size in 0..=n {
            if found {
                break;
            }

            // Iterate over all subsets of the given size
            let mut best_positions = Vec::new();
            for mask in 0u32..(1u32 << n) {
                if mask.count_ones() as usize != size {
                    continue;
                }

                let positions: Vec<usize> =
                    (0..n).filter(|&i| mask & (1 << i) != 0).collect();

                // Compute the type-count signature at these positions
                let mut sig = [0usize; 4];
                for &p in &positions {
                    sig[child_types[p].index()] += 1;
                }

                // Check if any other supertile type could produce the same
                // signature at a subset of its children of the same size
                let mut unique = true;
                for (other_idx, other_children) in all_child_types.iter().enumerate() {
                    if other_idx == st_idx {
                        continue;
                    }
                    // Can we pick `size` children from `other_children` with
                    // the same type-count signature?
                    if can_match_signature(other_children, &sig, size) {
                        unique = false;
                        break;
                    }
                }

                if unique {
                    best_positions = positions;
                    found = true;
                    break;
                }
            }

            if found {
                results.push(DeterminingSet {
                    supertile: st_type,
                    positions: best_positions.clone(),
                    size,
                });
            }
        }

        // Fallback: if no subset is unique (shouldn't happen), use all positions
        if !found {
            results.push(DeterminingSet {
                supertile: st_type,
                positions: (0..n).collect(),
                size: n,
            });
        }
    }

    results
}

/// Check if we can pick `size` elements from `types` whose type-count
/// signature matches `target_sig`.
fn can_match_signature(types: &[MetatileType], target_sig: &[usize; 4], size: usize) -> bool {
    if types.len() < size {
        return false;
    }

    // Count available types
    let mut available = [0usize; 4];
    for t in types {
        available[t.index()] += 1;
    }

    // Check: do we have enough of each type?
    let mut total_needed = 0usize;
    for i in 0..4 {
        if target_sig[i] > available[i] {
            return false;
        }
        total_needed += target_sig[i];
    }

    total_needed == size
}

// ---------------------------------------------------------------------------
// Erasure fuzzing
// ---------------------------------------------------------------------------

/// Result of an erasure trial at a given fraction.
#[derive(Clone, Debug)]
pub struct ErasureResult {
    pub fraction: f64,
    pub trials: usize,
    /// Mean fraction of tiles still recoverable across trials.
    pub mean_recoverable: f64,
    /// Standard deviation of recoverable fraction.
    pub std_recoverable: f64,
    /// Mean fraction of tiles that remain uniquely determined.
    pub mean_determined: f64,
}

/// Deterministic xorshift64 PRNG.
fn xorshift64(state: &mut u64) -> u64 {
    let mut x = *state;
    x ^= x << 13;
    x ^= x >> 7;
    x ^= x << 17;
    *state = x;
    x
}

/// Erase a fraction of tile types and measure how many remaining tiles
/// can still be uniquely assigned to their parent supertile.
pub fn erasure_sweep(
    hierarchy: &FlatHierarchy,
    level: usize,
    adjacency: &[Vec<usize>],
    fractions: &[f64],
    trials_per_fraction: usize,
) -> Vec<ErasureResult> {
    let n = hierarchy.tile_types[level].len();
    let mut results = Vec::new();

    for &frac in fractions {
        let mut recoverable_rates = Vec::with_capacity(trials_per_fraction);
        let mut determined_rates = Vec::with_capacity(trials_per_fraction);

        for trial in 0..trials_per_fraction {
            // Seed PRNG deterministically from fraction and trial
            let mut rng_state =
                (frac.to_bits() ^ (trial as u64).wrapping_mul(0x9E3779B97F4A7C15)) | 1;

            // Decide which tiles to erase
            let erase_count = (n as f64 * frac).round() as usize;
            let mut erased = vec![false; n];

            if erase_count >= n {
                erased.iter_mut().for_each(|e| *e = true);
            } else {
                // Fisher-Yates partial shuffle to pick erase_count indices
                let mut indices: Vec<usize> = (0..n).collect();
                for i in 0..erase_count {
                    let j = i + (xorshift64(&mut rng_state) as usize % (n - i));
                    indices.swap(i, j);
                }
                for &idx in &indices[..erase_count] {
                    erased[idx] = true;
                }
            }

            // Group non-erased tiles by masked signature to check determination
            let mut sig_groups: HashMap<(MetatileType, Vec<(usize, [usize; 4])>), HashSet<MetatileType>> =
                HashMap::new();
            let mut tile_sigs: Vec<Option<(MetatileType, Vec<(usize, [usize; 4])>)>> = vec![None; n];

            for tile in 0..n {
                if erased[tile] {
                    continue;
                }
                let own_type = hierarchy.tile_types[level][tile];
                let sig = masked_type_signature(hierarchy, adjacency, level, tile, 1, &erased);
                let parent = hierarchy.parent_of[level][tile];
                let parent_type = hierarchy.tile_types[level + 1][parent];
                let key = (own_type, sig);
                sig_groups.entry(key.clone()).or_default().insert(parent_type);
                tile_sigs[tile] = Some(key);
            }

            let mut determined = 0usize;
            for tile in 0..n {
                if erased[tile] {
                    continue;
                }
                if let Some(ref key) = tile_sigs[tile] {
                    if sig_groups[key].len() == 1 {
                        determined += 1;
                    }
                }
            }

            let surviving = n - erase_count.min(n);
            let rec_rate = if n > 0 {
                surviving as f64 / n as f64
            } else {
                1.0
            };
            let det_rate = if surviving > 0 {
                determined as f64 / surviving as f64
            } else {
                0.0
            };

            recoverable_rates.push(rec_rate);
            determined_rates.push(det_rate);
        }

        let mean_rec = mean(&recoverable_rates);
        let std_rec = std_dev(&recoverable_rates);
        let mean_det = mean(&determined_rates);

        results.push(ErasureResult {
            fraction: frac,
            trials: trials_per_fraction,
            mean_recoverable: mean_rec,
            std_recoverable: std_rec,
            mean_determined: mean_det,
        });
    }

    results
}

/// Type signature that ignores erased tiles.
fn masked_type_signature(
    hierarchy: &FlatHierarchy,
    adjacency: &[Vec<usize>],
    level: usize,
    tile: usize,
    radius: usize,
    erased: &[bool],
) -> Vec<(usize, [usize; 4])> {
    use std::collections::VecDeque;

    let mut visited: HashMap<usize, usize> = HashMap::new();
    let mut queue = VecDeque::new();
    queue.push_back((tile, 0usize));
    visited.insert(tile, 0);

    while let Some((current, dist)) = queue.pop_front() {
        if dist >= radius {
            continue;
        }
        for &neighbor in &adjacency[current] {
            if !visited.contains_key(&neighbor) {
                visited.insert(neighbor, dist + 1);
                queue.push_back((neighbor, dist + 1));
            }
        }
    }

    let mut by_distance: BTreeMap<usize, [usize; 4]> = BTreeMap::new();
    for (&tile_idx, &dist) in &visited {
        if erased[tile_idx] {
            continue;
        }
        let type_idx = hierarchy.tile_types[level][tile_idx].index();
        by_distance.entry(dist).or_insert([0; 4])[type_idx] += 1;
    }

    by_distance.into_iter().collect()
}

fn mean(values: &[f64]) -> f64 {
    if values.is_empty() {
        return 0.0;
    }
    values.iter().sum::<f64>() / values.len() as f64
}

fn std_dev(values: &[f64]) -> f64 {
    if values.len() < 2 {
        return 0.0;
    }
    let m = mean(values);
    let variance = values.iter().map(|v| (v - m).powi(2)).sum::<f64>() / (values.len() - 1) as f64;
    variance.sqrt()
}

// ---------------------------------------------------------------------------
// Dependency graph
// ---------------------------------------------------------------------------

/// Build a directed dependency graph: tile A depends on tile B if erasing B
/// changes A's determination status from determined to ambiguous.
pub fn build_dependency_graph(
    hierarchy: &FlatHierarchy,
    level: usize,
    adjacency: &[Vec<usize>],
    radius: usize,
) -> Vec<Vec<usize>> {
    let n = hierarchy.tile_types[level].len();

    // First compute the "baseline" signatures for all tiles (no erasures)
    let baseline_sigs: Vec<TypeSignature> = (0..n)
        .map(|i| type_signature(hierarchy, adjacency, level, i, radius))
        .collect();

    // Group tiles by baseline signature to find determined tiles
    let mut sig_to_parent_types: HashMap<&TypeSignature, HashSet<MetatileType>> = HashMap::new();
    for (i, sig) in baseline_sigs.iter().enumerate() {
        let parent = hierarchy.parent_of[level][i];
        let parent_type = hierarchy.tile_types[level + 1][parent];
        sig_to_parent_types.entry(sig).or_default().insert(parent_type);
    }

    let baseline_determined: Vec<bool> = baseline_sigs
        .iter()
        .map(|sig| sig_to_parent_types[sig].len() == 1)
        .collect();

    let mut deps: Vec<Vec<usize>> = vec![Vec::new(); n];

    // For each tile A that is determined at baseline...
    for a in 0..n {
        if !baseline_determined[a] {
            continue;
        }

        // Check each neighbor within radius: does erasing it make A ambiguous?
        let hood = neighborhood(adjacency, a, radius);
        for &b in &hood {
            if b == a {
                continue;
            }

            let mut erased = vec![false; n];
            erased[b] = true;

            let sig_a = masked_type_signature(hierarchy, adjacency, level, a, radius, &erased);

            // Check if this masked signature is still unique for A's parent type
            // We need to check against all other tiles' masked signatures
            // For efficiency, just check against tiles in A's neighborhood that
            // would have the same masked signature
            let own_type = hierarchy.tile_types[level][a];
            let parent_a = hierarchy.parent_of[level][a];
            let parent_type_a = hierarchy.tile_types[level + 1][parent_a];

            // Check all tiles with the same own type: do any with different
            // parent type produce the same masked signature?
            let mut ambiguous = false;
            for c in 0..n {
                if c == a || erased[c] {
                    continue;
                }
                if hierarchy.tile_types[level][c] != own_type {
                    continue;
                }
                let parent_c = hierarchy.parent_of[level][c];
                let parent_type_c = hierarchy.tile_types[level + 1][parent_c];
                if parent_type_c == parent_type_a {
                    continue;
                }

                let sig_c = masked_type_signature(hierarchy, adjacency, level, c, radius, &erased);
                if sig_c == sig_a {
                    ambiguous = true;
                    break;
                }
            }

            if ambiguous {
                deps[a].push(b);
            }
        }
    }

    deps
}

/// Summary of dependency cascade analysis.
#[derive(Clone, Debug)]
pub struct CascadeReport {
    /// Length of the longest dependency chain.
    pub max_chain_length: usize,
    /// Tile with the highest in-degree (most depended upon).
    pub max_in_degree_tile: Option<usize>,
    /// The highest in-degree value.
    pub max_in_degree: usize,
    /// Distribution: in-degree -> count of tiles.
    pub in_degree_distribution: BTreeMap<usize, usize>,
    /// Whether the dependency graph contains cycles.
    pub has_cycles: bool,
    /// Total number of dependency edges.
    pub total_edges: usize,
}

/// Analyze the dependency graph for cascading vulnerability.
pub fn cascade_analysis(deps: &[Vec<usize>]) -> CascadeReport {
    let n = deps.len();

    // In-degree computation
    let mut in_degree = vec![0usize; n];
    let mut total_edges = 0usize;
    for neighbors in deps {
        for &target in neighbors {
            in_degree[target] += 1;
            total_edges += 1;
        }
    }

    let max_in_degree_tile = in_degree
        .iter()
        .enumerate()
        .max_by_key(|(_, &d)| d)
        .filter(|(_, &d)| d > 0)
        .map(|(i, _)| i);
    let max_in_degree = in_degree.iter().copied().max().unwrap_or(0);

    let mut in_degree_distribution = BTreeMap::new();
    for &d in &in_degree {
        *in_degree_distribution.entry(d).or_insert(0usize) += 1;
    }

    // Cycle detection via DFS coloring
    let has_cycles = detect_cycles(deps);

    // Longest path via DFS (works even with cycles, just caps at n)
    let max_chain_length = longest_path(deps);

    CascadeReport {
        max_chain_length,
        max_in_degree_tile,
        max_in_degree,
        in_degree_distribution,
        has_cycles,
        total_edges,
    }
}

fn detect_cycles(deps: &[Vec<usize>]) -> bool {
    let n = deps.len();
    // 0 = unvisited, 1 = in progress, 2 = done
    let mut state = vec![0u8; n];

    for start in 0..n {
        if state[start] != 0 {
            continue;
        }
        let mut stack = vec![(start, 0usize)];
        state[start] = 1;

        while let Some((node, idx)) = stack.last_mut() {
            if *idx < deps[*node].len() {
                let next = deps[*node][*idx];
                *idx += 1;
                match state[next] {
                    0 => {
                        state[next] = 1;
                        stack.push((next, 0));
                    }
                    1 => return true, // back edge = cycle
                    _ => {}
                }
            } else {
                state[*node] = 2;
                stack.pop();
            }
        }
    }

    false
}

fn longest_path(deps: &[Vec<usize>]) -> usize {
    let n = deps.len();
    let mut memo = vec![None::<usize>; n];
    let mut visiting = vec![false; n];
    let mut max_len = 0usize;

    for start in 0..n {
        let len = longest_path_from(deps, start, &mut memo, &mut visiting);
        max_len = max_len.max(len);
    }

    max_len
}

fn longest_path_from(
    deps: &[Vec<usize>],
    node: usize,
    memo: &mut [Option<usize>],
    visiting: &mut [bool],
) -> usize {
    if let Some(cached) = memo[node] {
        return cached;
    }
    if visiting[node] {
        // Cycle detected, return 0 to avoid infinite recursion
        return 0;
    }

    visiting[node] = true;
    let mut max_child = 0usize;
    for &next in &deps[node] {
        let child_len = longest_path_from(deps, next, memo, visiting);
        max_child = max_child.max(child_len + 1);
    }
    visiting[node] = false;
    memo[node] = Some(max_child);
    max_child
}

// ---------------------------------------------------------------------------
// Full vulnerability analysis
// ---------------------------------------------------------------------------

/// Complete vulnerability analysis results.
pub struct VulnerabilityAnalysis {
    pub swaps: Vec<SwapRecord>,
    pub criticality: Vec<PositionCriticality>,
    pub determining_sets: Vec<DeterminingSet>,
    pub erasure_results: Vec<ErasureResult>,
    pub cascade: CascadeReport,
    pub depth: usize,
    pub base_tiles: usize,
}

/// Run the full vulnerability analysis.
pub fn analyze(depth: usize, erasure_trials: usize) -> VulnerabilityAnalysis {
    let swaps = enumerate_valid_swaps();
    let criticality = compute_position_criticality();
    let determining_sets = minimum_determining_sets();

    let hierarchy = build_flat_hierarchy(MetatileType::H, depth);
    let base_tiles = hierarchy.tile_types[0].len();
    let adjacency = full_sibling_adjacency(&hierarchy, 0);

    let fractions: Vec<f64> = (0..=10).map(|i| i as f64 / 10.0).collect();
    let erasure_results = erasure_sweep(&hierarchy, 0, &adjacency, &fractions, erasure_trials);

    let deps = build_dependency_graph(&hierarchy, 0, &adjacency, 1);
    let cascade = cascade_analysis(&deps);

    VulnerabilityAnalysis {
        swaps,
        criticality,
        determining_sets,
        erasure_results,
        cascade,
        depth,
        base_tiles,
    }
}

/// Print the vulnerability analysis report.
pub fn print_report(analysis: &VulnerabilityAnalysis) {
    println!("=== Recoverability Vulnerability Analysis ===\n");

    // Swap enumeration
    println!("--- Valid single-tile swaps ---");
    if analysis.swaps.is_empty() {
        println!("  No valid single-tile swaps between any supertile pair.");
    } else {
        println!(
            "  Found {} valid swap(s):",
            analysis.swaps.len()
        );
        for swap in &analysis.swaps {
            println!(
                "    {:?} ({} children) + 1 {:?} = {:?} ({} children)",
                swap.source_supertile,
                swap.source_size,
                swap.differing_type,
                swap.target_supertile,
                swap.source_size + 1,
            );
        }
    }

    // Criticality
    println!("\n--- Per-position criticality ---");
    for (st_idx, name) in SUPERTILE_NAMES.iter().enumerate() {
        let st_type = MetatileType::all()[st_idx];
        let positions: Vec<&PositionCriticality> = analysis
            .criticality
            .iter()
            .filter(|p| p.supertile == st_type)
            .collect();
        let critical_count = positions.iter().filter(|p| p.score == 1).count();
        let redundant_count = positions.iter().filter(|p| p.score == 0).count();
        println!(
            "  {} ({} children): {} critical, {} redundant",
            name,
            positions.len(),
            critical_count,
            redundant_count
        );
        for p in &positions {
            let status = if p.score == 0 { "redundant" } else { "CRITICAL" };
            let confused = if p.confused_with.is_empty() {
                String::new()
            } else {
                format!(
                    " (confused with {:?})",
                    p.confused_with
                )
            };
            println!(
                "    pos {} ({:?}): {}{}",
                p.position, p.child_type, status, confused
            );
        }
    }

    // Minimum determining sets
    println!("\n--- Minimum determining sets ---");
    for ds in &analysis.determining_sets {
        let name = SUPERTILE_NAMES[ds.supertile.index()];
        println!(
            "  {}: size {} (positions {:?})",
            name, ds.size, ds.positions
        );
    }

    // Erasure sweep
    println!("\n--- Erasure sweep (depth={}, {} base tiles) ---", analysis.depth, analysis.base_tiles);
    println!(
        "  {:>8} {:>12} {:>12}",
        "Fraction", "Surviving", "Determined"
    );
    for er in &analysis.erasure_results {
        println!(
            "  {:>8.1}% {:>11.1}% {:>11.1}%",
            er.fraction * 100.0,
            er.mean_recoverable * 100.0,
            er.mean_determined * 100.0,
        );
    }

    // Dependency graph
    println!("\n--- Dependency graph (radius 1) ---");
    println!("  Total edges: {}", analysis.cascade.total_edges);
    println!("  Has cycles: {}", analysis.cascade.has_cycles);
    println!(
        "  Max chain length: {}",
        analysis.cascade.max_chain_length
    );
    if let Some(tile) = analysis.cascade.max_in_degree_tile {
        println!(
            "  Most depended-upon tile: {} (in-degree {})",
            tile, analysis.cascade.max_in_degree
        );
    }
    println!("  In-degree distribution:");
    for (&degree, &count) in &analysis.cascade.in_degree_distribution {
        println!("    degree {}: {} tiles", degree, count);
    }

    // Summary
    println!("\n=== SUMMARY ===");
    let swap_count = analysis.swaps.len();
    let unique_swap_pairs: HashSet<(MetatileType, MetatileType)> = analysis
        .swaps
        .iter()
        .map(|s| {
            if s.source_supertile.index() < s.target_supertile.index() {
                (s.source_supertile, s.target_supertile)
            } else {
                (s.target_supertile, s.source_supertile)
            }
        })
        .collect();

    if swap_count > 0 {
        println!(
            "Vulnerable swap pair(s): {} ({} directional swaps between {} pair(s))",
            unique_swap_pairs
                .iter()
                .map(|(a, b)| format!("{:?}<->{:?}", a, b))
                .collect::<Vec<_>>()
                .join(", "),
            swap_count,
            unique_swap_pairs.len(),
        );
    }

    let total_critical: usize = analysis
        .criticality
        .iter()
        .filter(|p| p.score == 1)
        .count();
    let total_positions: usize = analysis.criticality.len();
    println!(
        "Critical positions: {}/{} ({:.1}%)",
        total_critical,
        total_positions,
        total_critical as f64 / total_positions as f64 * 100.0
    );

    // Phase transition estimate
    if let Some(transition) = analysis
        .erasure_results
        .windows(2)
        .find(|w| w[0].mean_determined > 0.5 && w[1].mean_determined <= 0.5)
    {
        println!(
            "Erasure phase transition: ~{:.0}%-{:.0}% erasure",
            transition[0].fraction * 100.0,
            transition[1].fraction * 100.0,
        );
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn only_pf_swap_exists() {
        let swaps = enumerate_valid_swaps();
        // P' and F' differ by exactly 1 F tile: P'=[2,0,1,2] (5 children),
        // F'=[2,0,1,3] (6 children). P' + 1F = F'. This is the only pair
        // whose compositions differ by exactly one tile.
        assert!(
            !swaps.is_empty(),
            "should find at least one valid swap"
        );

        let swap_pairs: HashSet<(MetatileType, MetatileType)> = swaps
            .iter()
            .map(|s| {
                let (a, b) = if s.source_supertile.index() < s.target_supertile.index() {
                    (s.source_supertile, s.target_supertile)
                } else {
                    (s.target_supertile, s.source_supertile)
                };
                (a, b)
            })
            .collect();

        assert_eq!(
            swap_pairs.len(),
            1,
            "should have exactly 1 unique swap pair, got: {:?}",
            swap_pairs
        );
        assert!(
            swap_pairs.contains(&(MetatileType::P, MetatileType::F)),
            "the only swap pair should be P<->F, got: {:?}",
            swap_pairs
        );
    }

    #[test]
    fn h_supertile_has_critical_position() {
        let crit = compute_position_criticality();
        let h_positions: Vec<&PositionCriticality> = crit
            .iter()
            .filter(|p| p.supertile == MetatileType::H)
            .collect();

        // H' has 10 children. The T-child is unique to H' (only supertile with T).
        // But the T position itself — when masked — should make H' look potentially
        // like another type. Actually H' is so distinctive that many positions are redundant.
        // At least verify we computed all 10.
        assert_eq!(h_positions.len(), 10, "H' should have 10 child positions");

        // Check that at least one position has a non-trivial analysis
        let has_critical = h_positions.iter().any(|p| p.score == 1);
        let has_redundant = h_positions.iter().any(|p| p.score == 0);
        // H' is large enough that some positions should be redundant
        assert!(
            has_critical || has_redundant,
            "H' should have at least some critical or redundant positions"
        );
    }

    #[test]
    fn t_supertile_single_child_is_critical() {
        let crit = compute_position_criticality();
        let t_positions: Vec<&PositionCriticality> = crit
            .iter()
            .filter(|p| p.supertile == MetatileType::T)
            .collect();

        assert_eq!(t_positions.len(), 1, "T' should have 1 child position");
        // T' has composition [1,0,0,0]. If we erase the single H child,
        // we have [0,0,0,0], which is the empty set — doesn't match any
        // other supertile via adding one tile (H' needs 10, P' needs 5, F' needs 6).
        // So T's child is actually redundant in a sense — but it depends on the
        // definition. With our definition (can adding 1 tile produce another
        // supertile's composition?), removing 1H from T' gives [0,0,0,0], and
        // adding 1 tile gives at most [1,0,0,0] or similar — which IS T' again.
        // No other supertile has composition reachable by [0,0,0,0]+1 tile.
        // So score should be 0 (redundant) — T' is so small it's unambiguous.
        assert_eq!(
            t_positions[0].score, 0,
            "T' single child should be redundant (T' is uniquely small)"
        );
    }

    #[test]
    fn minimum_determining_set_sizes() {
        let sets = minimum_determining_sets();
        assert_eq!(sets.len(), 4, "should have one determining set per supertile type");

        for ds in &sets {
            let name = SUPERTILE_NAMES[ds.supertile.index()];
            // All supertiles should have a determining set no larger than their child count
            let max_size = SUPERTILE_CHILDREN[ds.supertile.index()].len();
            assert!(
                ds.size <= max_size,
                "{} determining set size {} > child count {}",
                name,
                ds.size,
                max_size
            );
        }

        // T' has 1 child, should need at most 1
        let t_set = sets.iter().find(|d| d.supertile == MetatileType::T).unwrap();
        assert!(t_set.size <= 1, "T' should need at most 1 position");
    }

    #[test]
    fn erasure_at_zero_is_fully_recoverable() {
        let hierarchy = build_flat_hierarchy(MetatileType::H, 2);
        let adj = full_sibling_adjacency(&hierarchy, 0);
        let results = erasure_sweep(&hierarchy, 0, &adj, &[0.0], 1);

        assert_eq!(results.len(), 1);
        assert!(
            (results[0].mean_recoverable - 1.0).abs() < 1e-10,
            "0% erasure should mean 100% surviving, got {}",
            results[0].mean_recoverable
        );
        assert!(
            (results[0].mean_determined - 1.0).abs() < 1e-10,
            "0% erasure should mean 100% determined, got {}",
            results[0].mean_determined
        );
    }

    #[test]
    fn erasure_at_one_is_unrecoverable() {
        let hierarchy = build_flat_hierarchy(MetatileType::H, 2);
        let adj = full_sibling_adjacency(&hierarchy, 0);
        let results = erasure_sweep(&hierarchy, 0, &adj, &[1.0], 1);

        assert_eq!(results.len(), 1);
        assert!(
            results[0].mean_recoverable < 0.01,
            "100% erasure should leave ~0% surviving, got {}",
            results[0].mean_recoverable
        );
    }

    #[test]
    fn dependency_graph_structure() {
        let hierarchy = build_flat_hierarchy(MetatileType::H, 2);
        let adj = full_sibling_adjacency(&hierarchy, 0);
        let deps = build_dependency_graph(&hierarchy, 0, &adj, 1);

        assert_eq!(
            deps.len(),
            hierarchy.tile_types[0].len(),
            "dependency graph should have one entry per tile"
        );

        // All dependency targets should be valid tile indices
        let n = deps.len();
        for (tile, targets) in deps.iter().enumerate() {
            for &target in targets {
                assert!(
                    target < n,
                    "tile {} depends on out-of-range tile {}",
                    tile,
                    target
                );
            }
        }
    }

    #[test]
    fn criticality_scores_sum_correctly() {
        let crit = compute_position_criticality();

        // Total positions should equal sum of all supertile child counts
        let expected_total: usize = SUPERTILE_CHILDREN.iter().map(|c| c.len()).sum();
        assert_eq!(
            crit.len(),
            expected_total,
            "should have one criticality entry per child position across all supertile types"
        );

        // Every score should be 0 or 1
        for p in &crit {
            assert!(
                p.score <= 1,
                "criticality score should be 0 or 1, got {}",
                p.score
            );
        }
    }
}
